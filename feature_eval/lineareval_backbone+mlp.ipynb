{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Import packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "YUemQib7ZE4D"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets\n",
        "import sys\n",
        "sys.path.append(\"..\")\n",
        "from model.resnet_simclr import ResNetSimCLR\n",
        "from lars import LARS\n",
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDfbL3w_Z0Od",
        "outputId": "7532966e-1c4a-4641-c928-4cda14c53389"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda:6\n"
          ]
        }
      ],
      "source": [
        "device = 'cuda:6' if torch.cuda.is_available() else 'cpu'\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "arch = 'resnet50'\n",
        "dataset_name = 'cifar10'\n",
        "\n",
        "model = ResNetSimCLR(arch, 10)\n",
        "mlp_in_dim = model.mlp[0].in_features\n",
        "num_classes = 10\n",
        "model.mlp = torch.nn.Linear(mlp_in_dim, num_classes)\n",
        "\n",
        "# if arch == 'resnet18':\n",
        "#   model = torchvision.models.resnet18(pretrained=False, num_classes=10).to(device)\n",
        "# elif arch == 'resnet50':\n",
        "#   model = torchvision.models.resnet50(pretrained=False, num_classes=10).to(device)\n",
        "# print(model)\n",
        "\n",
        "epochs = 200\n",
        "batch_size = 256\n",
        "dataset = 'cifar10'\n",
        "lr = 1.0 * batch_size / 256\n",
        "eta_min = 1e-7\n",
        "w = 0\n",
        "\n",
        "num_workers = 8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Prepare DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "BfIPl0G6_RrT"
      },
      "outputs": [],
      "source": [
        "def get_stl10_data_loaders(download, shuffle=True, batch_size=batch_size):\n",
        "  train_dataset = datasets.STL10('../dataset', split='train', download=download,\n",
        "                                  transform=transforms.ToTensor())\n",
        "\n",
        "  train_loader = DataLoader(train_dataset, batch_size=batch_size,\n",
        "                            num_workers=num_workers, drop_last=True, shuffle=shuffle)\n",
        "  \n",
        "  test_dataset = datasets.STL10('../dataset', split='test', download=download,\n",
        "                                  transform=transforms.ToTensor())\n",
        "\n",
        "  test_loader = DataLoader(test_dataset, batch_size=2*batch_size,\n",
        "                            num_workers=num_workers, drop_last=True, shuffle=shuffle)\n",
        "  return train_loader, test_loader\n",
        "\n",
        "def get_cifar10_data_loaders(download, shuffle=True, batch_size=batch_size):\n",
        "  train_dataset = datasets.CIFAR10('../dataset', train=True, download=download,\n",
        "                                  transform=transforms.ToTensor())\n",
        "\n",
        "  train_loader = DataLoader(train_dataset, batch_size=batch_size,\n",
        "                            num_workers=num_workers, drop_last=True, shuffle=shuffle)\n",
        "  \n",
        "  test_dataset = datasets.CIFAR10('../dataset', train=False, download=download,\n",
        "                                  transform=transforms.ToTensor())\n",
        "\n",
        "  test_loader = DataLoader(test_dataset, batch_size=2*batch_size,\n",
        "                            num_workers=num_workers, drop_last=True, shuffle=shuffle)\n",
        "                            \n",
        "  return train_loader, test_loader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Modify SimCLR's checkpoint state_dict to fit ResNet Classification Task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "checkpoint = torch.load('../result/checkpoint/simclr/checkpoint_0100.pth.tar', map_location=device)\n",
        "state_dict = checkpoint['state_dict']\n",
        "for key in list(state_dict.keys()):\n",
        "    if key.startswith(\"mlp\"):\n",
        "        del state_dict[key]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "4AIfgq41GuTT"
      },
      "outputs": [],
      "source": [
        "# checkpoint = torch.load('../result/checkpoint/simclr/checkpoint_0100.pth.tar', map_location=device)\n",
        "# state_dict = checkpoint['state_dict']\n",
        "# for k in list(state_dict.keys()):\n",
        "#   if k.startswith('backbone.'):\n",
        "#     if k.startswith('backbone') and not k.startswith('backbone.fc'):\n",
        "#       # remove prefix\n",
        "#       state_dict[k[len(\"backbone.\"):]] = state_dict[k]\n",
        "#   del state_dict[k]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "VVjA83PPJYWl"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "_IncompatibleKeys(missing_keys=['mlp.weight', 'mlp.bias'], unexpected_keys=[])\n"
          ]
        }
      ],
      "source": [
        "log = model.load_state_dict(state_dict, strict=False)\n",
        "print(log)\n",
        "assert log.missing_keys == ['mlp.weight', 'mlp.bias']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117,
          "referenced_widgets": [
            "149b9ce8fb68473a837a77431c12281a",
            "88cd3db2831e4c13a4a634709700d6b2",
            "a88c31d74f5c40a2b24bcff5a35d216c",
            "60c6150177694717a622936b830427b5",
            "dba019efadee4fdc8c799f309b9a7e70",
            "5901c2829a554c8ebbd5926610088041",
            "957362a11d174407979cf17012bf9208",
            "a4f82234388e4701a02a9f68a177193a"
          ]
        },
        "id": "_GC0a14uWRr6",
        "outputId": "4c2558db-921c-425e-f947-6cc746d8c749"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Dataset: cifar10\n"
          ]
        }
      ],
      "source": [
        "if dataset_name == 'cifar10':\n",
        "  train_loader, test_loader = get_cifar10_data_loaders(download=True)\n",
        "elif dataset_name == 'stl10':\n",
        "  train_loader, test_loader = get_stl10_data_loaders(download=True)\n",
        "print(\"Dataset:\", dataset_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Frozen ResNet parameter and train a classifier on its hidden representation to eval SimCLR's performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "pYT_KsM0Mnnr"
      },
      "outputs": [],
      "source": [
        "# freeze all layers but the last fc\n",
        "for name, param in model.named_parameters():\n",
        "    if name not in ['mlp.weight', 'mlp.bias']:\n",
        "        param.requires_grad = False\n",
        "\n",
        "# filter(function, iterable)\n",
        "parameters = list(filter(lambda p: p.requires_grad, model.parameters()))\n",
        "assert len(parameters) == 2  # mlp.weight, mlp.bias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "aPVh1S_eMRDU"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Adjusting learning rate of group 0 to 1.0000e+00.\n"
          ]
        }
      ],
      "source": [
        "# optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=w)\n",
        "\n",
        "optimizer = LARS(model.parameters(), lr=lr, weight_decay=w, exclude_from_weight_decay=[\"batch_normalization\", \"bias\"])\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs, eta_min=eta_min, last_epoch=-1, verbose=True)\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "edr6RhP2PdVq"
      },
      "outputs": [],
      "source": [
        "def accuracy(output, target, topk=(1,)):\n",
        "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
        "    with torch.no_grad():\n",
        "        maxk = max(topk)\n",
        "        batch_size = target.size(0)\n",
        "\n",
        "        _, pred = output.topk(maxk, 1, True, True)\n",
        "        pred = pred.t()\n",
        "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "        res = []\n",
        "        for k in topk:\n",
        "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
        "            res.append(correct_k.mul_(100.0 / batch_size))\n",
        "        return res\n",
        "\n",
        "def MyAccuracy(logits, labels):\n",
        "    batch_size = logits.size()[0]\n",
        "    outputs = torch.functional.F.log_softmax(logits, dim=1)\n",
        "    predict = torch.max(outputs, dim=1)[1]\n",
        "    acc_count = torch.sum(predict == labels)\n",
        "    return acc_count / batch_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOder0dAMI7X",
        "outputId": "5f723b91-5a5e-43eb-ca01-a9b5ae2f1346"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0\tTop1 Train accuracy 13.790064811706543\tTop1 Test accuracy: 17.012746810913086 17.01274663209915 \tTop5 test acc: 63.88774871826172\n",
            "Epoch 1\tTop1 Train accuracy 18.840145111083984\tTop1 Test accuracy: 20.01439094543457 20.014391839504242 \tTop5 test acc: 68.82196044921875\n",
            "Epoch 2\tTop1 Train accuracy 20.951522827148438\tTop1 Test accuracy: 21.258224487304688 21.258224546909332 \tTop5 test acc: 71.0834732055664\n",
            "Epoch 3\tTop1 Train accuracy 22.08333396911621\tTop1 Test accuracy: 22.255346298217773 22.255346179008484 \tTop5 test acc: 71.82360076904297\n",
            "Epoch 4\tTop1 Train accuracy 23.195112228393555\tTop1 Test accuracy: 22.9029598236084 22.90296107530594 \tTop5 test acc: 72.31702423095703\n",
            "Epoch 5\tTop1 Train accuracy 23.882211685180664\tTop1 Test accuracy: 22.974918365478516 22.97491729259491 \tTop5 test acc: 72.38897705078125\n",
            "Epoch 6\tTop1 Train accuracy 24.433094024658203\tTop1 Test accuracy: 24.095394134521484 24.09539520740509 \tTop5 test acc: 73.71504974365234\n",
            "Epoch 7\tTop1 Train accuracy 25.01602554321289\tTop1 Test accuracy: 24.0748348236084 24.07483607530594 \tTop5 test acc: 73.99259948730469\n",
            "Epoch 8\tTop1 Train accuracy 25.360578536987305\tTop1 Test accuracy: 23.858964920043945 23.858964443206787 \tTop5 test acc: 73.85896301269531\n",
            "Epoch 9\tTop1 Train accuracy 25.79126739501953\tTop1 Test accuracy: 24.599096298217773 24.599096179008484 \tTop5 test acc: 74.34210205078125\n",
            "Epoch 10\tTop1 Train accuracy 26.272035598754883\tTop1 Test accuracy: 24.42434310913086 24.424342811107635 \tTop5 test acc: 74.88692474365234\n",
            "Epoch 11\tTop1 Train accuracy 26.20793342590332\tTop1 Test accuracy: 24.629934310913086 24.62993413209915 \tTop5 test acc: 74.1776351928711\n",
            "Epoch 12\tTop1 Train accuracy 26.470354080200195\tTop1 Test accuracy: 24.61965560913086 24.619655311107635 \tTop5 test acc: 74.73272705078125\n",
            "Epoch 13\tTop1 Train accuracy 26.84294891357422\tTop1 Test accuracy: 25.256990432739258 25.256991386413574 \tTop5 test acc: 74.9588851928711\n",
            "Epoch 14\tTop1 Train accuracy 26.91105842590332\tTop1 Test accuracy: 24.691612243652344 24.691611528396606 \tTop5 test acc: 75.04112243652344\n",
            "Epoch 15\tTop1 Train accuracy 27.111379623413086\tTop1 Test accuracy: 25.082237243652344 25.082236528396606 \tTop5 test acc: 75.02056121826172\n",
            "Epoch 16\tTop1 Train accuracy 27.574119567871094\tTop1 Test accuracy: 25.1439151763916 25.14391541481018 \tTop5 test acc: 75.37006378173828\n",
            "Epoch 17\tTop1 Train accuracy 27.485979080200195\tTop1 Test accuracy: 25.113075256347656 25.113075971603394 \tTop5 test acc: 75.0102767944336\n",
            "Epoch 18\tTop1 Train accuracy 27.506010055541992\tTop1 Test accuracy: 25.267269134521484 25.26727020740509 \tTop5 test acc: 75.06167602539062\n",
            "Epoch 19\tTop1 Train accuracy 27.83253288269043\tTop1 Test accuracy: 25.071956634521484 25.07195770740509 \tTop5 test acc: 75.46258544921875\n",
            "Epoch 20\tTop1 Train accuracy 27.95673179626465\tTop1 Test accuracy: 25.277549743652344 25.277549028396606 \tTop5 test acc: 74.7944107055664\n",
            "Epoch 21\tTop1 Train accuracy 27.9587345123291\tTop1 Test accuracy: 25.308387756347656 25.308388471603394 \tTop5 test acc: 75.25698852539062\n",
            "Epoch 22\tTop1 Train accuracy 27.850561141967773\tTop1 Test accuracy: 25.3392276763916 25.33922791481018 \tTop5 test acc: 75.32894897460938\n",
            "Epoch 23\tTop1 Train accuracy 28.257211685180664\tTop1 Test accuracy: 25.68873405456543 25.688734650611877 \tTop5 test acc: 75.9868392944336\n",
            "Epoch 24\tTop1 Train accuracy 28.116987228393555\tTop1 Test accuracy: 25.49342155456543 25.493422150611877 \tTop5 test acc: 75.69901275634766\n",
            "Epoch 25\tTop1 Train accuracy 28.287260055541992\tTop1 Test accuracy: 25.1953125 25.1953125 \tTop5 test acc: 75.09251403808594\n",
            "Epoch 26\tTop1 Train accuracy 28.671875\tTop1 Test accuracy: 25.061677932739258 25.061678886413574 \tTop5 test acc: 75.390625\n",
            "Epoch 27\tTop1 Train accuracy 28.251203536987305\tTop1 Test accuracy: 25.370065689086914 25.370067358016968 \tTop5 test acc: 75.06167602539062\n",
            "Epoch 28\tTop1 Train accuracy 28.407453536987305\tTop1 Test accuracy: 25.462581634521484 25.46258270740509 \tTop5 test acc: 75.12335205078125\n",
            "Epoch 29\tTop1 Train accuracy 28.515625\tTop1 Test accuracy: 25.863487243652344 25.863486528396606 \tTop5 test acc: 75.14391326904297\n",
            "Epoch 30\tTop1 Train accuracy 28.375402450561523\tTop1 Test accuracy: 25.308387756347656 25.308388471603394 \tTop5 test acc: 75.69901275634766\n",
            "Epoch 31\tTop1 Train accuracy 28.58173179626465\tTop1 Test accuracy: 25.421464920043945 25.421464443206787 \tTop5 test acc: 75.5859375\n",
            "Epoch 32\tTop1 Train accuracy 28.64583396911621\tTop1 Test accuracy: 25.657894134521484 25.65789520740509 \tTop5 test acc: 75.07196044921875\n",
            "Epoch 33\tTop1 Train accuracy 28.932292938232422\tTop1 Test accuracy: 25.431743621826172 25.431743264198303 \tTop5 test acc: 75.3803482055664\n",
            "Epoch 34\tTop1 Train accuracy 28.745994567871094\tTop1 Test accuracy: 25.770971298217773 25.770971179008484 \tTop5 test acc: 75.25698852539062\n",
            "Epoch 35\tTop1 Train accuracy 28.471555709838867\tTop1 Test accuracy: 25.113075256347656 25.113075971603394 \tTop5 test acc: 75.82237243652344\n",
            "Epoch 36\tTop1 Train accuracy 29.002405166625977\tTop1 Test accuracy: 25.328947067260742 25.328946113586426 \tTop5 test acc: 75.49342346191406\n",
            "Epoch 37\tTop1 Train accuracy 28.79006576538086\tTop1 Test accuracy: 25.894325256347656 25.894325971603394 \tTop5 test acc: 75.31866455078125\n",
            "Epoch 38\tTop1 Train accuracy 28.778045654296875\tTop1 Test accuracy: 25.308387756347656 25.308388471603394 \tTop5 test acc: 75.50370025634766\n",
            "Epoch 39\tTop1 Train accuracy 28.810096740722656\tTop1 Test accuracy: 25.256990432739258 25.256991386413574 \tTop5 test acc: 75.82237243652344\n",
            "Epoch 40\tTop1 Train accuracy 28.701923370361328\tTop1 Test accuracy: 25.472862243652344 25.472861528396606 \tTop5 test acc: 75.50370025634766\n",
            "Epoch 41\tTop1 Train accuracy 28.940305709838867\tTop1 Test accuracy: 25.370065689086914 25.370067358016968 \tTop5 test acc: 75.14391326904297\n",
            "Epoch 42\tTop1 Train accuracy 28.713943481445312\tTop1 Test accuracy: 25.575658798217773 25.575658679008484 \tTop5 test acc: 75.52426147460938\n",
            "Epoch 43\tTop1 Train accuracy 28.922277450561523\tTop1 Test accuracy: 25.071956634521484 25.07195770740509 \tTop5 test acc: 75.16447448730469\n",
            "Epoch 44\tTop1 Train accuracy 29.028446197509766\tTop1 Test accuracy: 25.0 25.0 \tTop5 test acc: 74.83552551269531\n",
            "Epoch 45\tTop1 Train accuracy 28.912260055541992\tTop1 Test accuracy: 25.349506378173828 25.349506735801697 \tTop5 test acc: 75.89432525634766\n",
            "Epoch 46\tTop1 Train accuracy 28.89423179626465\tTop1 Test accuracy: 25.133634567260742 25.133633613586426 \tTop5 test acc: 75.62705993652344\n",
            "Epoch 47\tTop1 Train accuracy 28.71194076538086\tTop1 Test accuracy: 25.8326473236084 25.83264708518982 \tTop5 test acc: 75.5448226928711\n",
            "Epoch 48\tTop1 Train accuracy 28.982372283935547\tTop1 Test accuracy: 25.380346298217773 25.380346179008484 \tTop5 test acc: 75.05139923095703\n",
            "Epoch 49\tTop1 Train accuracy 28.74399185180664\tTop1 Test accuracy: 25.565378189086914 25.565379858016968 \tTop5 test acc: 75.95600128173828\n",
            "Epoch 50\tTop1 Train accuracy 29.08253288269043\tTop1 Test accuracy: 25.01028060913086 25.010278820991516 \tTop5 test acc: 75.06167602539062\n",
            "Epoch 51\tTop1 Train accuracy 29.070514678955078\tTop1 Test accuracy: 25.5345401763916 25.53454041481018 \tTop5 test acc: 75.05139923095703\n",
            "Epoch 52\tTop1 Train accuracy 28.9743595123291\tTop1 Test accuracy: 25.030839920043945 25.030839443206787 \tTop5 test acc: 75.06167602539062\n",
            "Epoch 53\tTop1 Train accuracy 28.914262771606445\tTop1 Test accuracy: 25.68873405456543 25.688734650611877 \tTop5 test acc: 75.76068878173828\n",
            "Epoch 54\tTop1 Train accuracy 29.044471740722656\tTop1 Test accuracy: 25.565378189086914 25.565379858016968 \tTop5 test acc: 75.5448226928711\n",
            "Epoch 55\tTop1 Train accuracy 29.10256576538086\tTop1 Test accuracy: 25.49342155456543 25.493422150611877 \tTop5 test acc: 75.67845153808594\n",
            "Epoch 56\tTop1 Train accuracy 28.71194076538086\tTop1 Test accuracy: 25.29810905456543 25.298109650611877 \tTop5 test acc: 75.43174743652344\n",
            "Epoch 57\tTop1 Train accuracy 28.89423179626465\tTop1 Test accuracy: 24.9486026763916 24.94860142469406 \tTop5 test acc: 75.48313903808594\n",
            "Epoch 58\tTop1 Train accuracy 28.63982391357422\tTop1 Test accuracy: 25.575658798217773 25.575658679008484 \tTop5 test acc: 75.28782653808594\n",
            "Epoch 59\tTop1 Train accuracy 28.902244567871094\tTop1 Test accuracy: 24.8046875 24.8046875 \tTop5 test acc: 75.41118621826172\n",
            "Epoch 60\tTop1 Train accuracy 29.120594024658203\tTop1 Test accuracy: 25.719572067260742 25.719571113586426 \tTop5 test acc: 75.43174743652344\n",
            "Epoch 61\tTop1 Train accuracy 28.920272827148438\tTop1 Test accuracy: 25.842927932739258 25.842928886413574 \tTop5 test acc: 75.30838775634766\n",
            "Epoch 62\tTop1 Train accuracy 28.752004623413086\tTop1 Test accuracy: 25.5345401763916 25.53454041481018 \tTop5 test acc: 76.12047576904297\n",
            "Epoch 63\tTop1 Train accuracy 28.86819076538086\tTop1 Test accuracy: 24.845806121826172 24.845805764198303 \tTop5 test acc: 75.16447448730469\n",
            "Epoch 64\tTop1 Train accuracy 28.892229080200195\tTop1 Test accuracy: 24.958881378173828 24.958881735801697 \tTop5 test acc: 75.16447448730469\n",
            "Epoch 65\tTop1 Train accuracy 29.511219024658203\tTop1 Test accuracy: 24.958881378173828 24.958881735801697 \tTop5 test acc: 75.32894897460938\n",
            "Epoch 66\tTop1 Train accuracy 28.998397827148438\tTop1 Test accuracy: 25.380346298217773 25.380346179008484 \tTop5 test acc: 74.82524871826172\n",
            "Epoch 67\tTop1 Train accuracy 28.834135055541992\tTop1 Test accuracy: 24.794408798217773 24.794408679008484 \tTop5 test acc: 75.11307525634766\n",
            "Epoch 68\tTop1 Train accuracy 28.61779022216797\tTop1 Test accuracy: 25.49342155456543 25.493422150611877 \tTop5 test acc: 74.71217346191406\n",
            "Epoch 69\tTop1 Train accuracy 29.048479080200195\tTop1 Test accuracy: 25.2467098236084 25.24670958518982 \tTop5 test acc: 75.37006378173828\n",
            "Epoch 70\tTop1 Train accuracy 28.780048370361328\tTop1 Test accuracy: 25.349506378173828 25.349506735801697 \tTop5 test acc: 75.11307525634766\n",
            "Epoch 71\tTop1 Train accuracy 29.20673179626465\tTop1 Test accuracy: 25.0513973236084 25.05139708518982 \tTop5 test acc: 75.48313903808594\n",
            "Epoch 72\tTop1 Train accuracy 28.872196197509766\tTop1 Test accuracy: 25.2467098236084 25.24670958518982 \tTop5 test acc: 75.16447448730469\n",
            "Epoch 73\tTop1 Train accuracy 29.142629623413086\tTop1 Test accuracy: 24.290706634521484 24.29070770740509 \tTop5 test acc: 75.08223724365234\n",
            "Epoch 74\tTop1 Train accuracy 29.022436141967773\tTop1 Test accuracy: 25.09251594543457 25.092515349388123 \tTop5 test acc: 75.22615051269531\n",
            "Epoch 75\tTop1 Train accuracy 29.2868595123291\tTop1 Test accuracy: 24.81496810913086 24.814967811107635 \tTop5 test acc: 75.26727294921875\n",
            "Epoch 76\tTop1 Train accuracy 28.719953536987305\tTop1 Test accuracy: 25.030839920043945 25.030839443206787 \tTop5 test acc: 75.04112243652344\n",
            "Epoch 77\tTop1 Train accuracy 29.084535598754883\tTop1 Test accuracy: 24.70189094543457 24.701891839504242 \tTop5 test acc: 75.22615051269531\n",
            "Epoch 78\tTop1 Train accuracy 28.69190788269043\tTop1 Test accuracy: 25.1439151763916 25.14391541481018 \tTop5 test acc: 75.27754974365234\n",
            "Epoch 79\tTop1 Train accuracy 28.850160598754883\tTop1 Test accuracy: 24.773849487304688 24.773849546909332 \tTop5 test acc: 74.85608673095703\n",
            "Epoch 80\tTop1 Train accuracy 29.02444076538086\tTop1 Test accuracy: 25.411184310913086 25.41118562221527 \tTop5 test acc: 75.2055892944336\n",
            "Epoch 81\tTop1 Train accuracy 28.882211685180664\tTop1 Test accuracy: 25.7298526763916 25.72985291481018 \tTop5 test acc: 75.23643493652344\n",
            "Epoch 82\tTop1 Train accuracy 28.836137771606445\tTop1 Test accuracy: 25.061677932739258 25.061678886413574 \tTop5 test acc: 75.22615051269531\n",
            "Epoch 83\tTop1 Train accuracy 29.02043342590332\tTop1 Test accuracy: 25.185033798217773 25.185033679008484 \tTop5 test acc: 75.1953125\n",
            "Epoch 84\tTop1 Train accuracy 28.830129623413086\tTop1 Test accuracy: 25.431743621826172 25.431743264198303 \tTop5 test acc: 75.11307525634766\n",
            "Epoch 85\tTop1 Train accuracy 29.00841522216797\tTop1 Test accuracy: 25.01028060913086 25.010278820991516 \tTop5 test acc: 74.89720153808594\n",
            "Epoch 86\tTop1 Train accuracy 29.248798370361328\tTop1 Test accuracy: 25.308387756347656 25.308388471603394 \tTop5 test acc: 75.30838775634766\n",
            "Epoch 87\tTop1 Train accuracy 29.565305709838867\tTop1 Test accuracy: 25.236431121826172 25.236430764198303 \tTop5 test acc: 75.56537628173828\n",
            "Epoch 88\tTop1 Train accuracy 29.078527450561523\tTop1 Test accuracy: 25.20559310913086 25.205591320991516 \tTop5 test acc: 75.17475128173828\n",
            "Epoch 89\tTop1 Train accuracy 29.064504623413086\tTop1 Test accuracy: 24.886924743652344 24.886924028396606 \tTop5 test acc: 75.12335205078125\n",
            "Epoch 90\tTop1 Train accuracy 28.998397827148438\tTop1 Test accuracy: 24.81496810913086 24.814967811107635 \tTop5 test acc: 75.11307525634766\n",
            "Epoch 91\tTop1 Train accuracy 29.116586685180664\tTop1 Test accuracy: 25.524259567260742 25.524258613586426 \tTop5 test acc: 75.12335205078125\n",
            "Epoch 92\tTop1 Train accuracy 28.94230842590332\tTop1 Test accuracy: 25.020559310913086 25.02056062221527 \tTop5 test acc: 75.16447448730469\n",
            "Epoch 93\tTop1 Train accuracy 29.094552993774414\tTop1 Test accuracy: 24.537418365478516 24.53741729259491 \tTop5 test acc: 75.05139923095703\n",
            "Epoch 94\tTop1 Train accuracy 29.044471740722656\tTop1 Test accuracy: 25.226152420043945 25.226151943206787 \tTop5 test acc: 75.24671173095703\n",
            "Epoch 95\tTop1 Train accuracy 28.902244567871094\tTop1 Test accuracy: 25.123355865478516 25.12335479259491 \tTop5 test acc: 74.90748596191406\n",
            "Epoch 96\tTop1 Train accuracy 29.156652450561523\tTop1 Test accuracy: 25.174753189086914 25.174754858016968 \tTop5 test acc: 74.75328826904297\n",
            "Epoch 97\tTop1 Train accuracy 29.08654022216797\tTop1 Test accuracy: 24.917762756347656 24.917763471603394 \tTop5 test acc: 75.21587371826172\n",
            "Epoch 98\tTop1 Train accuracy 28.854167938232422\tTop1 Test accuracy: 25.59621810913086 25.596216320991516 \tTop5 test acc: 75.2055892944336\n",
            "Epoch 99\tTop1 Train accuracy 28.954328536987305\tTop1 Test accuracy: 25.370065689086914 25.370067358016968 \tTop5 test acc: 75.29811096191406\n",
            "Epoch 100\tTop1 Train accuracy 28.940305709838867\tTop1 Test accuracy: 24.866365432739258 24.866364896297455 \tTop5 test acc: 75.17475128173828\n",
            "Epoch 101\tTop1 Train accuracy 28.820112228393555\tTop1 Test accuracy: 25.5345401763916 25.53454041481018 \tTop5 test acc: 74.9897232055664\n",
            "Epoch 102\tTop1 Train accuracy 28.810096740722656\tTop1 Test accuracy: 24.372943878173828 24.372944235801697 \tTop5 test acc: 75.65789794921875\n",
            "Epoch 103\tTop1 Train accuracy 28.631811141967773\tTop1 Test accuracy: 25.544818878173828 25.544819235801697 \tTop5 test acc: 75.16447448730469\n",
            "Epoch 104\tTop1 Train accuracy 29.170673370361328\tTop1 Test accuracy: 24.5579776763916 24.55797642469406 \tTop5 test acc: 75.1541976928711\n",
            "Epoch 105\tTop1 Train accuracy 29.260818481445312\tTop1 Test accuracy: 25.061677932739258 25.061678886413574 \tTop5 test acc: 75.53453826904297\n",
            "Epoch 106\tTop1 Train accuracy 29.07251739501953\tTop1 Test accuracy: 24.599096298217773 24.599096179008484 \tTop5 test acc: 75.05139923095703\n",
            "Epoch 107\tTop1 Train accuracy 29.0625\tTop1 Test accuracy: 25.236431121826172 25.236430764198303 \tTop5 test acc: 75.21587371826172\n",
            "Epoch 108\tTop1 Train accuracy 29.43109130859375\tTop1 Test accuracy: 25.380346298217773 25.380346179008484 \tTop5 test acc: 74.90748596191406\n",
            "Epoch 109\tTop1 Train accuracy 28.940305709838867\tTop1 Test accuracy: 25.380346298217773 25.380346179008484 \tTop5 test acc: 75.08223724365234\n",
            "Epoch 110\tTop1 Train accuracy 29.10256576538086\tTop1 Test accuracy: 25.421464920043945 25.421464443206787 \tTop5 test acc: 75.45230102539062\n",
            "Epoch 111\tTop1 Train accuracy 28.992387771606445\tTop1 Test accuracy: 25.48314094543457 25.483140349388123 \tTop5 test acc: 74.57853698730469\n",
            "Epoch 112\tTop1 Train accuracy 29.016427993774414\tTop1 Test accuracy: 25.20559310913086 25.205591320991516 \tTop5 test acc: 74.83552551269531\n",
            "Epoch 113\tTop1 Train accuracy 29.080530166625977\tTop1 Test accuracy: 25.154193878173828 25.154194235801697 \tTop5 test acc: 74.58881378173828\n",
            "Epoch 114\tTop1 Train accuracy 28.780048370361328\tTop1 Test accuracy: 25.1953125 25.1953125 \tTop5 test acc: 75.13363647460938\n",
            "Epoch 115\tTop1 Train accuracy 29.022436141967773\tTop1 Test accuracy: 25.09251594543457 25.092515349388123 \tTop5 test acc: 74.62993621826172\n",
            "Epoch 116\tTop1 Train accuracy 29.010417938232422\tTop1 Test accuracy: 25.123355865478516 25.12335479259491 \tTop5 test acc: 74.68133544921875\n",
            "Epoch 117\tTop1 Train accuracy 29.034456253051758\tTop1 Test accuracy: 24.979440689086914 24.97944086790085 \tTop5 test acc: 74.67105102539062\n",
            "Epoch 118\tTop1 Train accuracy 28.64984130859375\tTop1 Test accuracy: 25.071956634521484 25.07195770740509 \tTop5 test acc: 75.1953125\n",
            "Epoch 119\tTop1 Train accuracy 28.80609130859375\tTop1 Test accuracy: 24.773849487304688 24.773849546909332 \tTop5 test acc: 75.70928955078125\n",
            "Epoch 120\tTop1 Train accuracy 29.232772827148438\tTop1 Test accuracy: 24.681331634521484 24.68133270740509 \tTop5 test acc: 75.08223724365234\n",
            "Epoch 121\tTop1 Train accuracy 29.3649845123291\tTop1 Test accuracy: 24.691612243652344 24.691611528396606 \tTop5 test acc: 75.0102767944336\n",
            "Epoch 122\tTop1 Train accuracy 29.188703536987305\tTop1 Test accuracy: 24.835527420043945 24.835526943206787 \tTop5 test acc: 75.02056121826172\n",
            "Epoch 123\tTop1 Train accuracy 28.918270111083984\tTop1 Test accuracy: 24.70189094543457 24.701891839504242 \tTop5 test acc: 75.33922576904297\n",
            "Epoch 124\tTop1 Train accuracy 29.33293342590332\tTop1 Test accuracy: 24.969161987304688 24.969162046909332 \tTop5 test acc: 74.86636352539062\n",
            "Epoch 125\tTop1 Train accuracy 28.854167938232422\tTop1 Test accuracy: 25.370065689086914 25.370067358016968 \tTop5 test acc: 75.49342346191406\n",
            "Epoch 126\tTop1 Train accuracy 28.976362228393555\tTop1 Test accuracy: 25.380346298217773 25.380346179008484 \tTop5 test acc: 75.37006378173828\n",
            "Epoch 127\tTop1 Train accuracy 28.986379623413086\tTop1 Test accuracy: 24.928043365478516 24.92804229259491 \tTop5 test acc: 75.29811096191406\n",
            "Epoch 128\tTop1 Train accuracy 29.244792938232422\tTop1 Test accuracy: 24.886924743652344 24.886924028396606 \tTop5 test acc: 75.1850357055664\n",
            "Epoch 129\tTop1 Train accuracy 28.914262771606445\tTop1 Test accuracy: 24.89720344543457 24.897204339504242 \tTop5 test acc: 74.83552551269531\n",
            "Epoch 130\tTop1 Train accuracy 28.86418342590332\tTop1 Test accuracy: 24.989721298217773 24.989721179008484 \tTop5 test acc: 74.82524871826172\n",
            "Epoch 131\tTop1 Train accuracy 29.00440788269043\tTop1 Test accuracy: 24.9486026763916 24.94860142469406 \tTop5 test acc: 74.8046875\n",
            "Epoch 132\tTop1 Train accuracy 28.908254623413086\tTop1 Test accuracy: 24.650493621826172 24.650493264198303 \tTop5 test acc: 74.62993621826172\n",
            "Epoch 133\tTop1 Train accuracy 29.2868595123291\tTop1 Test accuracy: 25.061677932739258 25.061678886413574 \tTop5 test acc: 75.50370025634766\n",
            "Epoch 134\tTop1 Train accuracy 29.014423370361328\tTop1 Test accuracy: 24.773849487304688 24.773849546909332 \tTop5 test acc: 74.90748596191406\n",
            "Epoch 135\tTop1 Train accuracy 29.120594024658203\tTop1 Test accuracy: 25.030839920043945 25.030839443206787 \tTop5 test acc: 74.77384948730469\n",
            "Epoch 136\tTop1 Train accuracy 29.048479080200195\tTop1 Test accuracy: 25.5859375 25.5859375 \tTop5 test acc: 74.7635726928711\n",
            "Epoch 137\tTop1 Train accuracy 29.028446197509766\tTop1 Test accuracy: 25.082237243652344 25.082236528396606 \tTop5 test acc: 75.1953125\n",
            "Epoch 138\tTop1 Train accuracy 29.11859130859375\tTop1 Test accuracy: 24.89720344543457 24.897204339504242 \tTop5 test acc: 75.10279846191406\n",
            "Epoch 139\tTop1 Train accuracy 29.02444076538086\tTop1 Test accuracy: 25.164474487304688 25.164473056793213 \tTop5 test acc: 75.47286224365234\n",
            "Epoch 140\tTop1 Train accuracy 29.276844024658203\tTop1 Test accuracy: 25.421464920043945 25.421464443206787 \tTop5 test acc: 74.84580993652344\n",
            "Epoch 141\tTop1 Train accuracy 29.038461685180664\tTop1 Test accuracy: 24.979440689086914 24.97944086790085 \tTop5 test acc: 75.06167602539062\n",
            "Epoch 142\tTop1 Train accuracy 29.11458396911621\tTop1 Test accuracy: 25.7298526763916 25.72985291481018 \tTop5 test acc: 75.42146301269531\n",
            "Epoch 143\tTop1 Train accuracy 28.830129623413086\tTop1 Test accuracy: 25.1953125 25.1953125 \tTop5 test acc: 74.5682601928711\n",
            "Epoch 144\tTop1 Train accuracy 28.954328536987305\tTop1 Test accuracy: 25.555099487304688 25.555098056793213 \tTop5 test acc: 74.82524871826172\n",
            "Epoch 145\tTop1 Train accuracy 28.667869567871094\tTop1 Test accuracy: 25.308387756347656 25.308388471603394 \tTop5 test acc: 74.8046875\n",
            "Epoch 146\tTop1 Train accuracy 29.028446197509766\tTop1 Test accuracy: 24.773849487304688 24.773849546909332 \tTop5 test acc: 74.86636352539062\n",
            "Epoch 147\tTop1 Train accuracy 28.97836685180664\tTop1 Test accuracy: 25.01028060913086 25.010278820991516 \tTop5 test acc: 75.12335205078125\n",
            "Epoch 148\tTop1 Train accuracy 29.112581253051758\tTop1 Test accuracy: 24.9486026763916 24.94860142469406 \tTop5 test acc: 74.7944107055664\n",
            "Epoch 149\tTop1 Train accuracy 29.02043342590332\tTop1 Test accuracy: 25.123355865478516 25.12335479259491 \tTop5 test acc: 74.78412628173828\n",
            "Epoch 150\tTop1 Train accuracy 29.11458396911621\tTop1 Test accuracy: 25.1439151763916 25.14391541481018 \tTop5 test acc: 75.17475128173828\n",
            "Epoch 151\tTop1 Train accuracy 28.95833396911621\tTop1 Test accuracy: 24.8046875 24.8046875 \tTop5 test acc: 75.11307525634766\n",
            "Epoch 152\tTop1 Train accuracy 29.018430709838867\tTop1 Test accuracy: 25.0513973236084 25.05139708518982 \tTop5 test acc: 74.74301147460938\n",
            "Epoch 153\tTop1 Train accuracy 29.136619567871094\tTop1 Test accuracy: 24.578536987304688 24.578537046909332 \tTop5 test acc: 74.92803955078125\n",
            "Epoch 154\tTop1 Train accuracy 29.162660598754883\tTop1 Test accuracy: 25.215871810913086 25.21587312221527 \tTop5 test acc: 74.8149642944336\n",
            "Epoch 155\tTop1 Train accuracy 28.798078536987305\tTop1 Test accuracy: 24.886924743652344 24.886924028396606 \tTop5 test acc: 74.5990982055664\n",
            "Epoch 156\tTop1 Train accuracy 29.010417938232422\tTop1 Test accuracy: 24.928043365478516 24.92804229259491 \tTop5 test acc: 75.32894897460938\n",
            "Epoch 157\tTop1 Train accuracy 29.038461685180664\tTop1 Test accuracy: 25.01028060913086 25.010278820991516 \tTop5 test acc: 74.64021301269531\n",
            "Epoch 158\tTop1 Train accuracy 28.956331253051758\tTop1 Test accuracy: 24.71217155456543 24.712170660495758 \tTop5 test acc: 74.90748596191406\n",
            "Epoch 159\tTop1 Train accuracy 28.990385055541992\tTop1 Test accuracy: 25.267269134521484 25.26727020740509 \tTop5 test acc: 75.81208801269531\n",
            "Epoch 160\tTop1 Train accuracy 29.148639678955078\tTop1 Test accuracy: 24.290706634521484 24.29070770740509 \tTop5 test acc: 74.97943878173828\n",
            "Epoch 161\tTop1 Train accuracy 28.95833396911621\tTop1 Test accuracy: 24.2701473236084 24.27014857530594 \tTop5 test acc: 75.45230102539062\n",
            "Epoch 162\tTop1 Train accuracy 28.956331253051758\tTop1 Test accuracy: 24.763568878173828 24.763569235801697 \tTop5 test acc: 74.78412628173828\n",
            "Epoch 163\tTop1 Train accuracy 29.044471740722656\tTop1 Test accuracy: 25.472862243652344 25.472861528396606 \tTop5 test acc: 75.66817474365234\n",
            "Epoch 164\tTop1 Train accuracy 29.13461685180664\tTop1 Test accuracy: 23.961759567260742 23.961760103702545 \tTop5 test acc: 75.07196044921875\n",
            "Epoch 165\tTop1 Train accuracy 28.97235679626465\tTop1 Test accuracy: 24.61965560913086 24.619655311107635 \tTop5 test acc: 75.24671173095703\n",
            "Epoch 166\tTop1 Train accuracy 29.094552993774414\tTop1 Test accuracy: 25.29810905456543 25.298109650611877 \tTop5 test acc: 74.71217346191406\n",
            "Epoch 167\tTop1 Train accuracy 29.278846740722656\tTop1 Test accuracy: 25.0513973236084 25.05139708518982 \tTop5 test acc: 75.05139923095703\n",
            "Epoch 168\tTop1 Train accuracy 28.944311141967773\tTop1 Test accuracy: 24.527137756347656 24.527138471603394 \tTop5 test acc: 75.25698852539062\n",
            "Epoch 169\tTop1 Train accuracy 28.94631576538086\tTop1 Test accuracy: 24.886924743652344 24.886924028396606 \tTop5 test acc: 74.77384948730469\n",
            "Epoch 170\tTop1 Train accuracy 28.918270111083984\tTop1 Test accuracy: 25.328947067260742 25.328946113586426 \tTop5 test acc: 74.96916198730469\n",
            "Epoch 171\tTop1 Train accuracy 29.104568481445312\tTop1 Test accuracy: 24.938322067260742 24.938322603702545 \tTop5 test acc: 75.23643493652344\n",
            "Epoch 172\tTop1 Train accuracy 28.75400733947754\tTop1 Test accuracy: 24.928043365478516 24.92804229259491 \tTop5 test acc: 74.94860076904297\n",
            "Epoch 173\tTop1 Train accuracy 28.866186141967773\tTop1 Test accuracy: 24.671052932739258 24.671052396297455 \tTop5 test acc: 74.66077423095703\n",
            "Epoch 174\tTop1 Train accuracy 29.018430709838867\tTop1 Test accuracy: 24.331825256347656 24.331825971603394 \tTop5 test acc: 74.43462371826172\n",
            "Epoch 175\tTop1 Train accuracy 28.826122283935547\tTop1 Test accuracy: 24.958881378173828 24.958881735801697 \tTop5 test acc: 74.94860076904297\n",
            "Epoch 176\tTop1 Train accuracy 28.68189239501953\tTop1 Test accuracy: 25.174753189086914 25.174754858016968 \tTop5 test acc: 75.51397705078125\n",
            "Epoch 177\tTop1 Train accuracy 28.9743595123291\tTop1 Test accuracy: 25.10279655456543 25.102797150611877 \tTop5 test acc: 74.86636352539062\n",
            "Epoch 178\tTop1 Train accuracy 29.140625\tTop1 Test accuracy: 24.928043365478516 24.92804229259491 \tTop5 test acc: 75.03083801269531\n",
            "Epoch 179\tTop1 Train accuracy 29.018430709838867\tTop1 Test accuracy: 24.989721298217773 24.989721179008484 \tTop5 test acc: 74.89720153808594\n",
            "Epoch 180\tTop1 Train accuracy 29.32091522216797\tTop1 Test accuracy: 24.845806121826172 24.845805764198303 \tTop5 test acc: 75.390625\n",
            "Epoch 181\tTop1 Train accuracy 28.830129623413086\tTop1 Test accuracy: 24.71217155456543 24.712170660495758 \tTop5 test acc: 74.73272705078125\n",
            "Epoch 182\tTop1 Train accuracy 28.918270111083984\tTop1 Test accuracy: 25.10279655456543 25.102797150611877 \tTop5 test acc: 75.49342346191406\n",
            "Epoch 183\tTop1 Train accuracy 29.090545654296875\tTop1 Test accuracy: 25.226152420043945 25.226151943206787 \tTop5 test acc: 75.17475128173828\n",
            "Epoch 184\tTop1 Train accuracy 29.210737228393555\tTop1 Test accuracy: 25.256990432739258 25.256991386413574 \tTop5 test acc: 74.94860076904297\n",
            "Epoch 185\tTop1 Train accuracy 29.03044891357422\tTop1 Test accuracy: 24.578536987304688 24.578537046909332 \tTop5 test acc: 74.8149642944336\n",
            "Epoch 186\tTop1 Train accuracy 29.308895111083984\tTop1 Test accuracy: 25.215871810913086 25.21587312221527 \tTop5 test acc: 74.73272705078125\n",
            "Epoch 187\tTop1 Train accuracy 28.934295654296875\tTop1 Test accuracy: 25.411184310913086 25.41118562221527 \tTop5 test acc: 74.9897232055664\n",
            "Epoch 188\tTop1 Train accuracy 29.41506576538086\tTop1 Test accuracy: 25.164474487304688 25.164473056793213 \tTop5 test acc: 75.0\n",
            "Epoch 189\tTop1 Train accuracy 29.02444076538086\tTop1 Test accuracy: 25.154193878173828 25.154194235801697 \tTop5 test acc: 75.9765625\n",
            "Epoch 190\tTop1 Train accuracy 28.97836685180664\tTop1 Test accuracy: 25.020559310913086 25.02056062221527 \tTop5 test acc: 74.77384948730469\n",
            "Epoch 191\tTop1 Train accuracy 29.234777450561523\tTop1 Test accuracy: 24.866365432739258 24.866364896297455 \tTop5 test acc: 74.62993621826172\n",
            "Epoch 192\tTop1 Train accuracy 28.872196197509766\tTop1 Test accuracy: 24.90748405456543 24.907483160495758 \tTop5 test acc: 74.74301147460938\n",
            "Epoch 193\tTop1 Train accuracy 29.29086685180664\tTop1 Test accuracy: 25.1953125 25.1953125 \tTop5 test acc: 75.13363647460938\n",
            "Epoch 194\tTop1 Train accuracy 28.747997283935547\tTop1 Test accuracy: 24.691612243652344 24.691611528396606 \tTop5 test acc: 75.08223724365234\n",
            "Epoch 195\tTop1 Train accuracy 29.06650733947754\tTop1 Test accuracy: 25.215871810913086 25.21587312221527 \tTop5 test acc: 75.03083801269531\n",
            "Epoch 196\tTop1 Train accuracy 29.354969024658203\tTop1 Test accuracy: 25.164474487304688 25.164473056793213 \tTop5 test acc: 75.07196044921875\n",
            "Epoch 197\tTop1 Train accuracy 29.092548370361328\tTop1 Test accuracy: 24.794408798217773 24.794408679008484 \tTop5 test acc: 75.11307525634766\n",
            "Epoch 198\tTop1 Train accuracy 28.866186141967773\tTop1 Test accuracy: 25.1953125 25.1953125 \tTop5 test acc: 75.1850357055664\n",
            "Epoch 199\tTop1 Train accuracy 28.820112228393555\tTop1 Test accuracy: 25.041118621826172 25.041118264198303 \tTop5 test acc: 74.8046875\n"
          ]
        }
      ],
      "source": [
        "model.to(device)\n",
        "for epoch in range(epochs):\n",
        "  model.train()\n",
        "\n",
        "  top1_train_accuracy = 0\n",
        "  \n",
        "  for counter, (x_batch, y_batch) in enumerate(train_loader):\n",
        "\n",
        "    x_batch = x_batch.to(device)\n",
        "    y_batch = y_batch.to(device)\n",
        "\n",
        "    logits = model(x_batch)\n",
        "    loss = criterion(logits, y_batch)\n",
        "    top1 = accuracy(logits, y_batch, topk=(1,))\n",
        "    top1_train_accuracy += top1[0]\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  top1_train_accuracy /= (counter + 1)\n",
        "\n",
        "  top1_accuracy = 0\n",
        "  top5_accuracy = 0\n",
        "  top1_my_acc = 0\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    for counter, (x_batch, y_batch) in enumerate(test_loader):\n",
        "\n",
        "      x_batch = x_batch.to(device)\n",
        "      y_batch = y_batch.to(device)\n",
        "\n",
        "      logits = model(x_batch)\n",
        "    \n",
        "      top1, top5 = accuracy(logits, y_batch, topk=(1,5))\n",
        "      top1_accuracy += top1[0]\n",
        "      top5_accuracy += top5[0]\n",
        "      top1_my_acc += MyAccuracy(logits, y_batch)\n",
        "    \n",
        "  top1_accuracy /= (counter + 1)\n",
        "  top5_accuracy /= (counter + 1)\n",
        "  top1_my_acc /= (counter + 1)\n",
        "  print(f\"Epoch {epoch}\\tTop1 Train accuracy {top1_train_accuracy.item()}\\tTop1 Test accuracy: {top1_accuracy.item()} {top1_my_acc.item()*100} \\tTop5 test acc: {top5_accuracy.item()}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "name": "Copy of mini-batch-logistic-regression-evaluator.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "e25216292d02bf44500672e9d401a59aad5b3be09f2bf77c8755263822999a2a"
    },
    "kernelspec": {
      "display_name": "pytorch",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "149b9ce8fb68473a837a77431c12281a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a88c31d74f5c40a2b24bcff5a35d216c",
              "IPY_MODEL_60c6150177694717a622936b830427b5"
            ],
            "layout": "IPY_MODEL_88cd3db2831e4c13a4a634709700d6b2"
          }
        },
        "5901c2829a554c8ebbd5926610088041": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60c6150177694717a622936b830427b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4f82234388e4701a02a9f68a177193a",
            "placeholder": "​",
            "style": "IPY_MODEL_957362a11d174407979cf17012bf9208",
            "value": " 2640404480/? [00:51&lt;00:00, 32685718.58it/s]"
          }
        },
        "88cd3db2831e4c13a4a634709700d6b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "957362a11d174407979cf17012bf9208": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a4f82234388e4701a02a9f68a177193a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a88c31d74f5c40a2b24bcff5a35d216c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "info",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5901c2829a554c8ebbd5926610088041",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dba019efadee4fdc8c799f309b9a7e70",
            "value": 1
          }
        },
        "dba019efadee4fdc8c799f309b9a7e70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
